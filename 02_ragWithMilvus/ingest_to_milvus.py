import re
import json
import os
import random
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
from openai import OpenAI
from pymilvus import (
    connections,
    FieldSchema, CollectionSchema, DataType,
    Collection, utility
)

# ----------------------------
# 1. è¿æ¥ Milvus
# ----------------------------
def connect_milvus(host: str = "localhost", port: str = "19530"):
    connections.connect(db_name="jobs_rag", host=host, port=port)
    print("âœ… Connected to Milvus")

# æœç´¢å’ŒæŸ¥è¯¢
# 1ã€å¤§æ¨¡å‹åˆå§‹åŒ–
openai_client = OpenAI(
	base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
	api_key=os.getenv("DASHSCOPE_API_KEY")
)

@dataclass
class JobItem:
    id: int
    title: str
    jobName: str
    jobSalary: str
    salaryMin: float
    salaryMax: float
    salaryUnit: str
    jobEdu: str
    eduLevel: int
    textForEmbedding: str
    embedding: List[float]

# ----------------------------
# 2. åˆ›å»º Collection
# ----------------------------
def create_collection(collection_name: str = "job_postings", dim: int = 1024):
    if utility.has_collection(collection_name):
        utility.drop_collection(collection_name)

    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=1000),
        FieldSchema(name="job_name", dtype=DataType.VARCHAR, max_length=500),
        FieldSchema(name="job_salary", dtype=DataType.VARCHAR, max_length=100),
        FieldSchema(name="salary_min", dtype=DataType.FLOAT),
        FieldSchema(name="salary_max", dtype=DataType.FLOAT),
        FieldSchema(name="salary_unit", dtype=DataType.VARCHAR, max_length=10),
        FieldSchema(name="job_edu", dtype=DataType.VARCHAR, max_length=100),
        FieldSchema(name="edu_level", dtype=DataType.INT16),
        FieldSchema(name="text_for_embedding", dtype=DataType.VARCHAR, max_length=2000),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dim)
    ]

    schema = CollectionSchema(fields, description="Job postings for RAG")
    collection = Collection(collection_name, schema)

    # åˆ›å»ºå‘é‡ç´¢å¼•
    index_params = {
        "index_type": "HNSW",
        "metric_type": "COSINE",
        "params": {"M": 8, "efConstruction": 64}
    }
    collection.create_index("embedding", index_params)
    print(f"âœ… Collection '{collection_name}' created with dim={dim}")
    return collection

# ----------------------------
# 3. è–ªèµ„è§£æå‡½æ•°
# ----------------------------
def parse_salary(salary_str: str) -> Tuple[Optional[float], Optional[float], str]:
    salary_str = salary_str.strip()
    if "é¢è®®" in salary_str or "åå•†" in salary_str:
        return None, None, "é¢è®®"

    salary_clean = salary_str.lower().replace("w", "k").replace("ä¸‡", "k")
    pattern = r'(\d+\.?\d*)\s*[-~]\s*(\d+\.?\d*)\s*[kK]\s*/\s*(å¹´|æœˆ)'
    match = re.search(pattern, salary_clean)
    if not match:
        single_pattern = r'(\d+\.?\d*)\s*[kK]\s*/\s*(å¹´|æœˆ)'
        smatch = re.search(single_pattern, salary_clean)
        if smatch:
            val = float(smatch.group(1))
            unit = smatch.group(2)
            if unit == "å¹´":
                val = val * 10 / 12
                unit = "æœˆ"
            return val, val, unit
        return None, None, "unknown"

    low, high, unit = match.groups()
    low, high = float(low), float(high)
    if unit == "å¹´":
        low = low * 10 / 12
        high = high * 10 / 12
        unit = "æœˆ"
    return low, high, unit

# ----------------------------
# 4. å­¦å†ç­‰çº§æ˜ å°„
# ----------------------------
def edu_to_level(edu_str: str) -> int:
    edu_str = edu_str.strip()
    if any(kw in edu_str for kw in ["åšå£«"]):
        return 3
    elif any(kw in edu_str for kw in ["ç¡•å£«", "ç ”ç©¶ç”Ÿ", "ç¡•å£«ä»¥ä¸Š", "ç ”ç©¶ç”Ÿä»¥ä¸Š"]):
        return 2
    elif "æœ¬ç§‘" in edu_str:
        return 1
    else:
        return 0

# ----------------------------
# 5. ç”Ÿæˆç”¨äº embedding çš„æ–‡æœ¬
# ----------------------------
def extract_company_from_title(title: str) -> str:
    match = re.search(r'ã€[^ã€‘]+ã€‘([^ï¼Œ,]+)', title)
    if match:
        return match.group(1).strip()
    return "æœªçŸ¥å…¬å¸"

def build_embedding_text(title: str, job_name: str, job_salary: str, job_edu: str) -> str:
    company = extract_company_from_title(title)
    return f"å²—ä½ï¼š{job_name}ï¼›å…¬å¸ï¼š{company}ï¼›è–ªèµ„ï¼š{job_salary}ï¼›å­¦å†è¦æ±‚ï¼š{job_edu}"

# ----------------------------
# 6. æ¨¡æ‹Ÿ embeddingï¼ˆå®é™…åº”æ›¿æ¢ä¸ºçœŸå®æ¨¡å‹ï¼‰
# ----------------------------
def generate_dummy_embedding(text: str, dim: int = 768) -> List[float]:
    return [random.random() for _ in range(dim)]

# 3ã€å®šä¹‰æ–‡æœ¬embeddingå¤„ç†å‡½æ•°
def generate_real_embedding(text):
    return (
        openai_client.embeddings.create(input=text, model="text-embedding-v3")
        .data[0]
        .embedding
    )


# ----------------------------
# 7. æ•°æ®é¢„å¤„ç†ä¸æ’å…¥
# ----------------------------
def preprocess_and_insert(
    raw_data: List[Dict],
    collection: Collection,
    embedding_dim: int = 768
):
    ## å°†entitieså®šä¹‰ä¸ºä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„çš„æ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ªæ•°æ®é¡¹
    entities = []


    for item in raw_data:
        title = item["title"]
        for job in item["jobDetails"]:
            job_name = job["jobName"]
            job_salary = job["jobSalary"]
            job_edu = job["jobEdu"]

            min_sal, max_sal, unit = parse_salary(job_salary)
            if min_sal is None:
                min_sal = -1.0
                max_sal = -1.0

            edu_lvl = edu_to_level(job_edu)
            embed_text = build_embedding_text(title, job_name, job_salary, job_edu)
            embed_vec = generate_real_embedding(embed_text)

            entities.append(
                {
                    "title": title,
                    "job_name": job_name,
                    "job_salary": job_salary,
                    "salary_min": min_sal,
                    "salary_max": max_sal,
                    "salary_unit": unit,
                    "job_edu": job_edu,
                    "edu_level": edu_lvl,
                    "text_for_embedding": embed_text,
                    "embedding": embed_vec
                }
            )

    # ä¿®å¤ï¼šç¡®ä¿ entities æ˜¯æ­£ç¡®æ ¼å¼
    try:
        collection.insert(entities)
        collection.flush()
        print(f"âœ… Inserted {len(entities)} job records into Milvus")
    except Exception as e:
        print(f"âŒ Insertion failed: {e}")
        raise

# ----------------------------
# 8. ä»æ–‡ä»¶è¯»å– JSON æ•°æ®
# ----------------------------
def load_json_data(file_path: str = "jobs.json") -> List[Dict]:
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        print(f"âœ… Loaded {len(data)} job postings from '{file_path}'")
        return data
    except FileNotFoundError:
        print(f"âŒ File '{file_path}' not found!")
        raise
    except json.JSONDecodeError as e:
        print(f"âŒ Invalid JSON in '{file_path}': {e}")
        raise

# ----------------------------
# 9. ä¸»ç¨‹åº
# ----------------------------
if __name__ == "__main__":
    JOBS_FILE = "jobs.json"          # â† ä»è¿™é‡Œè¯»å–
    COLLECTION_NAME = "job_postings"
    EMBEDDING_DIM = 1024

    # 1. è¯»å–æ•°æ®
    raw_data = load_json_data(JOBS_FILE)

    # 2. è¿æ¥å¹¶åˆ›å»º collection
    connect_milvus()
    collection = create_collection(COLLECTION_NAME, EMBEDDING_DIM)

    # 3. é¢„å¤„ç†å¹¶æ’å…¥
    preprocess_and_insert(raw_data, collection, EMBEDDING_DIM)

    # 4. éªŒè¯
    print(f"ğŸ“Š Total entities in collection: {collection.num_entities}")